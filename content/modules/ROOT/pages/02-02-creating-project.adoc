= Creating your project and pipeline server
include::_attributes.adoc[]

As a preliminary step, each of you is going to

. Create a Data Science project
** this will help keep your things together

. Create a Data Connection
** we need that for the pipeline server to store its artifacts

. Deploy a Data Science Pipeline Server
** we will need one, and it's better to create it from the start

. Launch a Workbench
** we will use it to review content and notebooks and to run the lab exercises to optimize the model.

. Clone the git repo into your Workbench
** this contains all the code from the prototype

The instructions below will guide you through these steps. Follow them carefully.

== Create a project

* First, in the OpenShift AI Dashboard application, navigate to the Data Science Projects menu on the left:
+
[.bordershadow]
image::02/02-02-ds-proj-nav.png[]

* Create a project with the **same name** as your user id
** You have been assigned a unique user ID:  `{user}`
** You need to now create a project with the exact same name: `{user}`
+
IMPORTANT: Your assigned user is {user}. Don't mess that up or things will break later on

* Leave the resource name unchanged
* Optionally, enter your first and last name in the description of the project.
* It should look like this:
+
[.bordershadow]
image::02/02-02-create-project.png[]
+
IMPORTANT: It should **NOT** be `userX` like in the screenshot. (for you, `X` should be a number instead)

== Create a Data Connection for the pipeline server

* We have deployed an instance of Minio in the cluster to act as a simple Object Storage for our purposes.
* You will need to **create connection** that points to it.
+
[.bordershadow]
image::02/02-02-add-dc.png[]

* You need to select the connection type, in this case **S3 compatible object storage -v1**
+
[.bordershadow]
image::02/02-02-add-dc-type.png[]

* Here is the information you need to enter:
** Name:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
Minio - models
** Access Key:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
{user}
** Secret Key:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
{password}
** Endpoint:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
http://minio-service.wksp-{user}.svc.cluster.local:9000
** Region:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
none
** Bucket:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
{user}
+
IMPORTANT: Once again, the bucket you will use has to match with the user ID you were provided

* The result should look similar to:
+
[.bordershadow]
image::02/data-connection.png[]

== Create a Pipeline Server

It is highly recommended to create your pipeline server before creating a workbench. So let's do that now!

* In your Data Science Pipeline (project `{user}`), or in your Data Science Project, **Pipelines**, click on **Configure pipeline server**
+
[.bordershadow]
image::02/02-02-pipelineserver01.png[]

* Use the same information as in the Data Connection created earlier (**Minio - models**) and click the **Configure pipeline server** button:
+
[.bordershadow]
image::02/02-02-pipelineserver02.png[]

* When your pipeline server is ready, your screen will look like the following:
+
[.bordershadow]
image::02/02-02-pipelineserver03.png[]

At this point, your pipeline server is ready and deployed.
